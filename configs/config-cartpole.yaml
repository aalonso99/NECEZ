# Basic params
env_name: "CartPole-v1"
obs_type: "cartpole"
exp_name: "cartpole"
seed: 0
obs_size: [4]

# Setup params  
log_dir: "runs"
log_name: "None"
load_buffer: False
debug: True
train_speed_profiling: False
get_batch_profiling: False
render: False
print_simple: True
max_games: 800 # Total number of games before training is ended
max_total_frames: 10_000
max_frames: 200 # Maximum frames for a single game before it is cut short
try_cuda: False # Whether to use cuda if available (makes training slower on cartpole)

# NEC and Transfer Learning
nec: False
pretrained: False
weights_path: "pretrained_weights.pt"

# Model params
latent_size: 6  # 16
support_width: 25
n_simulations: 30

# Training params
initial_learning_rate: 0.02
final_learning_rate: 0.002
tr_steps_before_lr_decay: 8_000
weight_decay: 0.0001
grad_clip: 1 # 0 interpreted as no clipping
val_weight: 0.25
policy_weight: 1.0
reward_weight: 1.0
batch_size: 32

# Search params
root_dirichlet_alpha: 0.3
explore_frac: 0.25
discount: 0.997
n_batches: 100
rollout_depth: 5
reward_depth: 30
buffer_size: 200

# Priority replay params
priority_replay: True
priority_alpha: 0.6
initial_priority_beta: 0.4
final_priority_beta: 1.0

# Temperature schedule
temp1: 1_000 # Steps after which temperature is dropped to 0.5
temp2: 2_000 # Steps after which temperature is dropped to 0.25
temp3: 3_000 # Steps after which temperature is dropped to 0

# Reanalyse
reanalyse: True
reanalyse_n: 1
prior_weight: 1
momentum: 0.9

## EfficientZero Additions
# Value prefix
value_prefix: True
lstm_hidden_size: 16

# Off policy correction
off_policy_correction: True
tau: 0.3
reward_steps: 1000
total_training_steps: 10_000

# Consistency loss
consistency_loss: True
#consistency_weight: 2.0
#consistency_weight: 0.5
consistency_weight: 5.0
